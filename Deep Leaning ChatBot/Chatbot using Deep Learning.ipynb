{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Chatbot Application using Deep Learning and PyTorch**"
      ],
      "metadata": {
        "id": "J7f4j1gcig38"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIT8Grez9wq9",
        "outputId": "917140b1-b313-4a32-8dfb-d4277f757c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "R8eyiHRs-N45"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "DMGCmhROfEPz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "iS1WnfaA-bRg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(sentence):\n",
        "  return nltk.word_tokenize(sentence)"
      ],
      "metadata": {
        "id": "wsS_NHAg94Qc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem(tokenized_sentence):\n",
        "  return stemmer.stem(tokenized_sentence)"
      ],
      "metadata": {
        "id": "KfcwLWgF-Mj0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bag_of_words(tokenized_sent, vocab):\n",
        "  tokenized_sent = [stem(w) for w in tokenized_sent]\n",
        "  bag = np.zeros(len(vocab), dtype = np.float32)\n",
        "  for idx,w in enumerate(vocab):\n",
        "    if w in tokenized_sent:\n",
        "      bag[idx] = 1.0\n",
        "  return bag"
      ],
      "metadata": {
        "id": "2Yp-D_eoer2h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words  = [stem(w) for w in tokenizer(\"Hello, how are you doing?\")]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX6Tdn80-Bjg",
        "outputId": "8a05be6f-2070-48a6-f257-df61cb2addd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', ',', 'how', 'are', 'you', 'do', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing json data for the chatbot\n",
        "\n",
        "import json"
      ],
      "metadata": {
        "id": "vqPJXcUI_N51"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/ChatBot\")\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql4TwLPtBA7u",
        "outputId": "2a9ec47a-09fd-4ee8-8d3c-2dd470e9c90d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['intents.json', 'NLTK.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('intents.json') as json_file:\n",
        "    intents = json.load(json_file)"
      ],
      "metadata": {
        "id": "2WW2dzQiBdrs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJKs7-WZBnzG",
        "outputId": "acc5dbda-38b1-4b0b-e813-38acc5251a33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'context_set': '',\n",
              "   'patterns': ['Hi',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hello',\n",
              "    'Good day',\n",
              "    'Whats up'],\n",
              "   'responses': ['Hello!',\n",
              "    'Good to see you again!',\n",
              "    'Hi there, how can I help?'],\n",
              "   'tag': 'greeting'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['cya',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'I am Leaving',\n",
              "    'Have a Good day'],\n",
              "   'responses': ['Sad to see you go :(', 'Talk to you later', 'Goodbye!'],\n",
              "   'tag': 'goodbye'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['how old',\n",
              "    'how old is tim',\n",
              "    'what is your age',\n",
              "    'how old are you',\n",
              "    'age?'],\n",
              "   'responses': ['I am 27 years old!', '27 years young!'],\n",
              "   'tag': 'age'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['what is your name',\n",
              "    'what should I call you',\n",
              "    'whats your name?'],\n",
              "   'responses': ['You can call me Pointer.', \"I'm pointer!\"],\n",
              "   'tag': 'name'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['Id like to buy something',\n",
              "    'whats on the menu',\n",
              "    'what do you reccommend?',\n",
              "    'could i get something to eat'],\n",
              "   'responses': ['We sell chocolate chip cookies for $2!',\n",
              "    'Cookies are on the menu!'],\n",
              "   'tag': 'shop'},\n",
              "  {'context_set': '',\n",
              "   'patterns': ['when are you guys open',\n",
              "    'what are your hours',\n",
              "    'hours of operation'],\n",
              "   'responses': ['We are open 7am-4pm Monday-Friday!'],\n",
              "   'tag': 'hours'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATE TRAINING DATA\n",
        "Tokenize -> lowering+stem -> exclude punctuation chars -> Bag of Words"
      ],
      "metadata": {
        "id": "ySyVyjtgBuyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = []\n",
        "tags = []\n",
        "data = []"
      ],
      "metadata": {
        "id": "LSEbvzraB4T7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents['intents']:\n",
        "  tag = intent['tag']\n",
        "  tags.append(tag)\n",
        "  for i in intent['patterns']:\n",
        "    w = tokenizer(i)\n",
        "    vocabulary.extend(w)\n",
        "    data.append((w,tag))"
      ],
      "metadata": {
        "id": "6qk8AoaOIvan"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z5-dWM2MWix",
        "outputId": "330f8918-2822-425d-961a-83fd576041ef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['greeting', 'goodbye', 'age', 'name', 'shop', 'hours']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation = ['?',',','.','!']\n",
        "vocabulary = [stem(w.lower()) for w in vocabulary if w not in punctuation]\n",
        "vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZVbT8WyMYjo",
        "outputId": "a1da9783-b85a-49fb-98a7-9421f337df77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi',\n",
              " 'how',\n",
              " 'are',\n",
              " 'you',\n",
              " 'is',\n",
              " 'anyon',\n",
              " 'there',\n",
              " 'hello',\n",
              " 'good',\n",
              " 'day',\n",
              " 'what',\n",
              " 'up',\n",
              " 'cya',\n",
              " 'see',\n",
              " 'you',\n",
              " 'later',\n",
              " 'goodby',\n",
              " 'i',\n",
              " 'am',\n",
              " 'leav',\n",
              " 'have',\n",
              " 'a',\n",
              " 'good',\n",
              " 'day',\n",
              " 'how',\n",
              " 'old',\n",
              " 'how',\n",
              " 'old',\n",
              " 'is',\n",
              " 'tim',\n",
              " 'what',\n",
              " 'is',\n",
              " 'your',\n",
              " 'age',\n",
              " 'how',\n",
              " 'old',\n",
              " 'are',\n",
              " 'you',\n",
              " 'age',\n",
              " 'what',\n",
              " 'is',\n",
              " 'your',\n",
              " 'name',\n",
              " 'what',\n",
              " 'should',\n",
              " 'i',\n",
              " 'call',\n",
              " 'you',\n",
              " 'what',\n",
              " 'your',\n",
              " 'name',\n",
              " 'id',\n",
              " 'like',\n",
              " 'to',\n",
              " 'buy',\n",
              " 'someth',\n",
              " 'what',\n",
              " 'on',\n",
              " 'the',\n",
              " 'menu',\n",
              " 'what',\n",
              " 'do',\n",
              " 'you',\n",
              " 'reccommend',\n",
              " 'could',\n",
              " 'i',\n",
              " 'get',\n",
              " 'someth',\n",
              " 'to',\n",
              " 'eat',\n",
              " 'when',\n",
              " 'are',\n",
              " 'you',\n",
              " 'guy',\n",
              " 'open',\n",
              " 'what',\n",
              " 'are',\n",
              " 'your',\n",
              " 'hour',\n",
              " 'hour',\n",
              " 'of',\n",
              " 'oper']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = sorted(set(vocabulary))"
      ],
      "metadata": {
        "id": "k81cNwtIN-FY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = sorted(set(tags))"
      ],
      "metadata": {
        "id": "_UZdeca8OHYa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=[]\n",
        "y_train = []"
      ],
      "metadata": {
        "id": "Pv8wUtUbOJ7X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (pattern_sent,tag) in data:\n",
        "  bag = bag_of_words(pattern_sent,vocabulary)\n",
        "  X_train.append(bag)\n",
        "  label = tags.index(tag)\n",
        "  y_train.append(label)   #cross entropy loss doesnt need one-hot encoded labels"
      ],
      "metadata": {
        "id": "sVLKCvGogLno"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "HvpXLWiQgt1V"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2T3q1DxQWwj",
        "outputId": "89ea2058-77c0-4b9b-d0c9-db97f9c710d9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating PyTorch dataset"
      ],
      "metadata": {
        "id": "ff0PvWm4fvGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "L0xf3oUvf0U_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.n_samples = len(X_train)\n",
        "    self.x_data = X_train\n",
        "    self.y_data = y_train\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "_Qyg8gAcgFHC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "batch_size = 8\n",
        "hidden_size = 8\n",
        "output_size = len(tags)\n",
        "input_size = len(X_train[0])\n",
        "learning_rate =0.001\n",
        "num_epochs =1000"
      ],
      "metadata": {
        "id": "-3wULOVCji25"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_size, len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMPg2ZXjmfDw",
        "outputId": "1ee2a9e8-d169-455b-bbcd-08a7a0292488"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_size, tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQOgv8HLmokO",
        "outputId": "7d028165-2f6c-4a16-d7b8-0efbcfe470df"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 ['age', 'goodbye', 'greeting', 'hours', 'name', 'shop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "N3-lzefVjZ70"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model training\n",
        "#feed forward nn with 2 hidden layers\n",
        "#bagof words as input to ip layer (number of different patterns as input size), \n",
        "#output layer equals number of different classes, then softmax activation\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size,hidden_size)  #creating 3 linear layers\n",
        "    self.l2 = nn.Linear(hidden_size,hidden_size)\n",
        "    self.l3 = nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out = self.l3(out)\n",
        "    #no activation and no softmax\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T3xQlnitkRno"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  #GPU availability check\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtDNyy7om_wh",
        "outputId": "41097e7e-6d46-4fc8-9174-c565457d9d8a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(input_size, hidden_size,output_size).to(device)\n",
        "\n",
        "#loss and optimizer \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters() ,lr = learning_rate)"
      ],
      "metadata": {
        "id": "FTKlyVZFbAhp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for (words,labels) in train_loader:\n",
        "    words = words.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    outputs = model(words)\n",
        "    loss = criterion(outputs,labels)\n",
        "\n",
        "    #backward and optimizer step\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  if (epoch + 1)%100 == 0:\n",
        "    print(f'epoch {epoch+1}/{num_epochs},loss = {loss.item():.4f}') \n",
        "\n",
        "print(f'final loss,loss = {loss.item():.4f}') \n",
        "\n"
      ],
      "metadata": {
        "id": "6bLWPY-olsSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a209560f-6b55-47ba-e59f-f52d62261d6e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 100/1000,loss = 1.3864\n",
            "epoch 200/1000,loss = 0.3182\n",
            "epoch 300/1000,loss = 0.0447\n",
            "epoch 400/1000,loss = 0.0053\n",
            "epoch 500/1000,loss = 0.0055\n",
            "epoch 600/1000,loss = 0.0020\n",
            "epoch 700/1000,loss = 0.0045\n",
            "epoch 800/1000,loss = 0.0019\n",
            "epoch 900/1000,loss = 0.0009\n",
            "epoch 1000/1000,loss = 0.0012\n",
            "final loss,loss = 0.0012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data  = {\n",
        "    \"model_state\":model.state_dict(),\n",
        "    \"input_size\":input_size,\n",
        "    \"output_size\":output_size,\n",
        "    \"hidden_size\":hidden_size,\n",
        "    \"vocabulary\":vocabulary,\n",
        "    \"tags\":tags\n",
        "}\n",
        " \n",
        "FILE = \"data.pth\"\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(f'training completed, File saved to {FILE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xn5HJ-Pc5pb",
        "outputId": "a51d1a96-fec3-4257-986a-8ccd909ee90d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training completed, File saved to data.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHAT BOT "
      ],
      "metadata": {
        "id": "ixMlaW-YeCdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n"
      ],
      "metadata": {
        "id": "zC_YkGpQd7-9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "vocab = data[\"vocabulary\"]\n",
        "tags = data[\"tags\"]\n",
        "model_state = data[\"model_state\"]"
      ],
      "metadata": {
        "id": "WnJ21goXeIEg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  NeuralNet(input_size,hidden_size,output_size)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD54oxYuexbd",
        "outputId": "6738ea9c-e0ed-4045-932c-64985fbc08fa"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=47, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=6, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING THE CHAT"
      ],
      "metadata": {
        "id": "gsuua7OqfL9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bot_name = \"Aravind\"\n",
        "print(\"Let's Talk! Type 'quit' to exit :)\")\n",
        "\n",
        "while True:\n",
        "  sentence = input(\"You: \")\n",
        "  if sentence == 'quit':\n",
        "    break\n",
        "  sentence = tokenizer(sentence)\n",
        "  X = bag_of_words(sentence,vocab)\n",
        "  X = X.reshape(1,X.shape[0])\n",
        "  X = torch.from_numpy(X)\n",
        "\n",
        "  output = model(X)\n",
        "  _,predicted = torch.max(output, dim=1)\n",
        "  tag = tags[predicted.item()]\n",
        "\n",
        "  probs = torch.softmax(output,dim=1)\n",
        "  prob = probs[0][predicted.item()]\n",
        "\n",
        "  if prob.item() > 0.75:\n",
        "    for intent in intents[\"intents\"]:\n",
        "      if tag == intent[\"tag\"]:\n",
        "        print(f'{bot_name}: {random.choice(intent[\"responses\"])}')\n",
        "  else:\n",
        "    print(f'{bot_name}: Sorry, I do not understand :(')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYlLh2mOfEjb",
        "outputId": "b0825f3c-8bc9-4385-938a-10fd01b1777f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's Talk! Type 'quit' to exit :)\n",
            "You: hi\n",
            "Aravind: Hi there, how can I help?\n",
            "You: how are you\n",
            "Aravind: Good to see you again!\n",
            "You: opening time?\n",
            "Aravind: Hello!\n",
            "You: opening time?\n",
            "Aravind: Good to see you again!\n",
            "You: time?\n",
            "Aravind: Good to see you again!\n",
            "You: hour?\n",
            "Aravind: Sorry, I do not understand :(\n",
            "You: menu?\n",
            "Aravind: Hi there, how can I help?\n",
            "You: whats on the menu\n",
            "Aravind: We sell chocolate chip cookies for $2!\n",
            "You: opening?\n",
            "Aravind: Hello!\n",
            "You: open hour\n",
            "Aravind: We are open 7am-4pm Monday-Friday!\n",
            "You: quit\n"
          ]
        }
      ]
    }
  ]
}